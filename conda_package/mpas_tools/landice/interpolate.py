import sys
import numpy as np
import netCDF4
import argparse
import math
from collections import OrderedDict
import scipy.spatial
import scipy.sparse
import time
from datetime import datetime


def interpolate_to_mpasli_grid():
    """
    Interpolate fields from an input file to a pre-existing MPAS-LI grid.

    The input file can either be CISM format or MPASLI format.

    For CISM input files, three interpolation methods are supported:
    * a built-in bilinear interpolation method
    * a built-in barycentric interpolation method (nearest neighbor is used
      for extrapolation regions)
    * using weights generated by ESMF

    For MPAS input files only barycentric interpolation is supported.

    The ESMF interpolation method can be used to interpolate from history
    files of other E3SM components by using the ESMF weight mapping files used
    in the E3SM coupler.  You will likely need to add your own variable
    mappings in the dictionary for the 'other' filetype at the end of this
    script.

    Multiple time levels can be interpolated using the --timestart and
    --timeend options. Default is to copy the first time level from the source
    file to the first time level of the destination file.  If multiple time
    levels are used, they are translated directly from the source to the
    destination.

    NOTE: There is no processing of actual time stamps!

    NOTE: xtime is NOT copied and must be copied manually, if desired!
    """

    # ----------------------------
    # ----------------------------
    # Define needed functions
    # ----------------------------
    # ----------------------------

    def _esmf_interp(sourceField):
        # Interpolates from the sourceField to the destinationField using ESMF
        # weights
        destinationField = np.zeros(xCell.shape)  # fields on cells only
        try:
            # Convert the source field into the SciPy Compressed Sparse Row
            # matrix format. This needs some reshaping to get the matching
            # dimensions
            source_csr = scipy.sparse.csr_matrix(
                sourceField.flatten()[:, np.newaxis])
            # Use SciPy CSR dot product - much faster than iterating over
            # elements of the full matrix
            destinationField = weights_csr.dot(source_csr).toarray().squeeze()
            # For conserve remapping, need to normalize by destination area
            # fraction. It should be safe to do this for other methods
            ind = np.where(dst_frac > 0.0)[0]
            destinationField[ind] /= dst_frac[ind]
        except:
            print('error in ESMF_interp')
        return destinationField

    # ----------------------------

    def _bilinear_interp(Value, gridType):
        # Calculate bilinear interpolation of Value field from x, y to new
        # ValueCell field (return value)  at xCell, yCell
        # This assumes that x, y, Value are regular CISM style grids and xCell,
        # yCell, ValueCell are 1-D unstructured MPAS style grids

        ValueCell = np.zeros(xCell.shape)

        if gridType == 'x0':
            x = x0
            y = y0
        elif gridType == 'x1':
            x = x1
            y = y1
        else:
            raise ValueError('unknown CISM grid type specified.')
        dx = x[1] - x[0]
        dy = y[1] - y[0]
        for i in range(len(xCell)):
            # Calculate the CISM grid cell indices (these are the lower index)
            xgrid = int(math.floor((xCell[i]-x[0]) / dx))
            if xgrid >= len(x) - 1:
                xgrid = len(x) - 2
            elif xgrid < 0:
                xgrid = 0
            ygrid = int(math.floor((yCell[i]-y[0]) / dy))
            if ygrid >= len(y) - 1:
                ygrid = len(y) - 2
            elif ygrid < 0:
                ygrid = 0
            # print(xgrid, ygrid, i)
            ValueCell[i] = (
                Value[ygrid, xgrid] * (x[xgrid+1] - xCell[i]) * (y[ygrid+1] - yCell[i]) / (dx * dy) +
                Value[ygrid+1, xgrid] * (x[xgrid+1] - xCell[i]) * (yCell[i] - y[ygrid]) / (dx * dy) +
                Value[ygrid, xgrid+1] * (xCell[i] - x[xgrid]) * (y[ygrid+1] - yCell[i]) / (dx * dy) +
                Value[ygrid+1, xgrid+1] * (xCell[i] - x[xgrid]) * (yCell[i] - y[ygrid]) / (dx * dy))
        return ValueCell

    # ----------------------------

    def _delaunay_interp_weights(xy, uv, d=2):
        """
        xy = input x,y coords
        uv = output (MPSALI) x,y coords
        """

        # print("scipy version=", scipy.version.full_version)
        if xy.shape[0] > 2**24-1:
            print("WARNING: The source file contains more than 2^24-1 "
                  "(16,777,215) points due to a limitation in older versions "
                  "of Qhull (see: https://mail.scipy.org/pipermail/scipy-user/2015-June/036598.html).  "
                  "Delaunay creation may fail if Qhull being linked by "
                  "scipy.spatial is older than v2015.0.1 2015/8/31.")

        tri = scipy.spatial.Delaunay(xy)
        print("    Delaunay triangulation complete.")
        simplex = tri.find_simplex(uv)
        print("    find_simplex complete.")
        vertices = np.take(tri.simplices, simplex, axis=0)
        print("    identified vertices.")
        temp = np.take(tri.transform, simplex, axis=0)
        print("    np.take complete.")
        delta = uv - temp[:, d]
        bary = np.einsum('njk,nk->nj', temp[:, :d, :], delta)
        print("    calculating bary complete.")
        wts = np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))

        # Now figure out if there is any extrapolation.
        # Find indices to points of output file that are outside of convex
        # hull of input points
        outsideInd = np.nonzero(tri.find_simplex(uv) < 0)
        outsideCoords = uv[outsideInd]
        # print(outsideInd)
        nExtrap = len(outsideInd[0])
        if nExtrap > 0:
            print(f"    Found {nExtrap} points requiring extrapolation. "
                  f"Using nearest neighbor extrapolation for those.")

        # Now find nearest neighbor for each outside point
        # Use KDTree of input points
        tree = scipy.spatial.cKDTree(xy)

        return vertices, wts, outsideInd, tree

    # ----------------------------

    def _nn_interp_weights(xy, uv, d=2):
        """
        xy = input x,y coords
        uv = output (MPSALI) x,y coords
        Note: could separate out building tree and interpolation for
              efficiency if many fields need to be processed
        """
        tree = scipy.spatial.cKDTree(xy)
        # k is the number of nearest neighbors.
        dist, idx = tree.query(uv, k=1)
        # # 2d cism fields need to be flattened. (Note the indices were
        # # flattened during init, so this just matches that operation for the
        # # field data itself.)  1d mpas fields do not, but the operation won't
        # # do anything because they are already flat.
        # outfield = values.flatten()[idx]
        return idx

    # ----------------------------

    def _delaunay_interpolate(values, gridType):
        if gridType == 'x0':
            vtx = vtx0
            wts = wts0
            tree = treex0
            outsideInd = outsideIndx0
        elif gridType == 'x1':
            vtx = vtx1
            wts = wts1
            outsideInd = outsideIndx1
            tree = treex1
        elif gridType == 'cell':
            vtx = vtCell
            wts = wtsCell
            outsideInd = outsideIndcell
            tree = treecell
        else:
            raise ValueError('unknown input file grid type specified.')

        outfield = np.einsum('nj,nj->n', np.take(values, vtx), wts)

        # Now apply nearest neighbor to points outside convex hull
        # We could have this enabled/disabled with a command line option, but
        # for now it will always be done.
        # Note: the barycentric interp applied above could be restricted to the
        #       points inside the convex hull instead of being applied to ALL
        #       points as is currently implemented.  However it is assumed that
        #       "redoing" the outside points has a small performance cost
        #       because there generally should be few such points and the
        #       implementation is much simpler this way.
        outsideCoord = mpasXY[outsideInd, :]
        if len(outsideInd) > 0:
            # k is the number of nearest neighbors.  Could crank this up to 2
            # (and then average them) with some fiddling, but keeping it simple
            # for now.
            dist, idx = tree.query(outsideCoord, k=1)

            # 2d cism fields need to be flattened. (Note the indices were
            # flattened during init, so this just matches that operation for
            # the field data itself.)  1d mpas fields do not, but the operation
            # won't do anything because they are already flat.
            outfield[outsideInd] = values.flatten()[idx]
        return outfield

    # ----------------------------

    def _interpolate_field(MPASfieldName):

        if fieldInfo[MPASfieldName]['gridType'] == 'x0' and \
                args.interpType == 'e':
            raise ValueError("This CISM field is on the staggered grid, and "
                             "currently this script does not support a second "
                             "ESMF weight file for the staggered grid.")

        InputFieldName = fieldInfo[MPASfieldName]['InputName']
        if filetype == 'cism':
            if 'time' in inputFile.variables[InputFieldName].dimensions:
                InputField = inputFile.variables[InputFieldName][timelev, :, :]
            else:
                if timelev > 0:
                    raise ValueError(
                       "--timestart and/or --timeend were specified but the "
                       "required time dimension of 'time' was not found in "
                       "the source file.")
                InputField = inputFile.variables[InputFieldName][:, :]
        elif filetype == 'mpas':
            if 'Time' in inputFile.variables[InputFieldName].dimensions:
                InputField = inputFile.variables[InputFieldName][timelev, :]
            else:
                if timelev > 0:
                    raise ValueError(
                       "--timestart and/or --timeend were specified but the "
                       "required time dimension of 'Time' was not found in "
                       "the source file.")
                InputField = inputFile.variables[InputFieldName][:]
        elif filetype == 'other':
            if 'time' in inputFile.variables[InputFieldName].dimensions:
                InputField = inputFile.variables[InputFieldName][timelev, :, :]
            else:
                if timelev > 0:
                    raise ValueError(
                       "--timestart and/or --timeend were specified but the "
                       "required time dimension of 'time' was not found in "
                       "the source file.")
                InputField = inputFile.variables[InputFieldName][:, :]

        print(f'  Input field  {InputFieldName} min/max: {InputField.min()} '
              f'{InputField.max()}')

        # Call the appropriate routine for actually doing the interpolation
        if args.interpType == 'b':
            print(f"  ...Interpolating to {MPASfieldName} using built-in "
                  f"bilinear method...")
            MPASfield = _bilinear_interp(
               InputField, fieldInfo[MPASfieldName]['gridType'])
        elif args.interpType == 'd':
            print(f"  ...Interpolating to {MPASfieldName} using barycentric  "
                  f"method...")
            MPASfield = _delaunay_interpolate(
               InputField, fieldInfo[MPASfieldName]['gridType'])
        elif args.interpType == 'n':
            print(f"  ...Interpolating to {MPASfieldName} using nearest "
                  f"neighbor method...")
            if fieldInfo[MPASfieldName]['gridType'] == 'x0':
                # 2d cism fields need to be flattened. (Note the indices were
                # flattened during init, so this just matches that operation
                # for the field data itself.)  1d mpas fields do not, but the
                # operation won't do anything because they are already flat.
                MPASfield = InputField.flatten()[nn_idx_x0]
            elif fieldInfo[MPASfieldName]['gridType'] == 'x1':
                # 2d cism fields need to be flattened. (Note the indices were
                # flattened during init, so this just matches that operation
                # for the field data itself.)  1d mpas fields do not, but the
                # operation won't do anything because they are already flat.
                MPASfield = InputField.flatten()[nn_idx_x1]
            elif fieldInfo[MPASfieldName]['gridType'] == 'cell':
                # 2d cism fields need to be flattened. (Note the indices were
                # flattened during init, so this just matches that operation
                # for the field data itself.)  1d mpas fields do not, but the
                # operation won't do anything because they are already flat.
                MPASfield = InputField.flatten()[nn_idx_cell]
        elif args.interpType == 'e':
            print(f"  ...Interpolating to {MPASfieldName} using ESMF-weights  "
                  f"method...")
            MPASfield = _esmf_interp(InputField)
        else:
            raise ValueError('Unknown interpolation method specified')

        print(f'  interpolated MPAS {MPASfieldName} min/max: '
              f'{MPASfield.min()} {MPASfield.max()}')

        if fieldInfo[MPASfieldName]['scalefactor'] != 1.0:
            MPASfield *= fieldInfo[MPASfieldName]['scalefactor']
            print(f'  scaled MPAS {MPASfieldName} min/max: '
                  f'{MPASfield.min()} {MPASfield.max()}')
        if fieldInfo[MPASfieldName]['offset'] != 0.0:
            MPASfield += fieldInfo[MPASfieldName]['offset']
            print(f'  offset MPAS {MPASfieldName} min/max: '
                  f'{MPASfield.min()} {MPASfield.max()}')

        return MPASfield

    # ----------------------------

    def _interpolate_field_with_layers(MPASfieldName):

        if fieldInfo[MPASfieldName]['gridType'] == 'x0' and \
                args.interpType == 'e':
            raise ValueError("This CISM field is on the staggered grid, and "
                             "currently this script does not support a second "
                             "ESMF weight file for the staggered grid.")

        InputFieldName = fieldInfo[MPASfieldName]['InputName']
        if filetype == 'cism':
            if 'time' in inputFile.variables[InputFieldName].dimensions:
                InputField = \
                    inputFile.variables[InputFieldName][timelev, :, :, :]
            else:
                if timelev > 0:
                    raise ValueError(
                        "--timestart and/or --timeend were specified but the "
                        "required time dimension of 'time' was not found in "
                        "the source file.")
                InputField = inputFile.variables[InputFieldName][:, :, :]
            # vertical index is the first (since we've eliminated time already)
            inputVerticalDimSize = InputField.shape[0]
            # second dimension is the vertical one - get the name of it
            layerFieldName = inputFile.variables[InputFieldName].dimensions[1]
            input_layers = inputFile.variables[layerFieldName][:]
        elif filetype == 'mpas':
            if 'Time' in inputFile.variables[InputFieldName].dimensions:
                InputField = inputFile.variables[InputFieldName][timelev, :, :]
            else:
                if timelev > 0:
                    raise ValueError(
                        "--timestart and/or --timeend were ""specified but "
                        "the required time dimension of 'Time' was not found "
                        "in the source file.")
                InputField = inputFile.variables[InputFieldName][:, :]
            # vertical index is the second (since we've eliminated time
            # already)
            inputVerticalDimSize = InputField.shape[1]
            layerThicknessFractions = \
                inputFile.variables['layerThicknessFractions'][:]
            # build MPAS sigma levels at center of each layer
            input_layers = np.zeros((inputVerticalDimSize,))
            if inputVerticalDimSize == len(layerThicknessFractions):
                print("  Using layer centers for the vertical coordinate of "
                      "this field.")
                input_layers[0] = layerThicknessFractions[0] * 0.5
                for k in range(1, inputVerticalDimSize):
                    input_layers[k] = (
                        input_layers[k-1] +
                        0.5 * layerThicknessFractions[k-1] +
                        0.5 * layerThicknessFractions[k])
                layerFieldName = \
                    '(sigma levels calculated from layerThicknessFractions)'
            elif inputVerticalDimSize == len(layerThicknessFractions)+1:
                print("  Using layer interfaces for the vertical coordinate "
                      "of this field.")
                input_layers[0] = 0.0
                for k in range(1, inputVerticalDimSize):
                    input_layers[k] = (
                        input_layers[k-1] + layerThicknessFractions[k-1])
            else:
                raise ValueError("\nUnknown vertical dimension for this "
                                 "variable source file.")
        else:
            raise ValueError("Fields with vertical layers can only be "
                             "interpolated using the barycentric or bilinear "
                             "methods.")

        # create array for interpolated source field at all layers
        # make it the size of the CISM vertical layers, but the MPAS horizontal
        #  locations
        mpas_grid_input_layers = np.zeros((inputVerticalDimSize, nCells))

        for z in range(inputVerticalDimSize):
            if filetype == 'cism':
                print(
                    f'  Input layer {z}, layer {InputFieldName} min/max: '
                    f'{InputField[z, :, :].min()} {InputField[z, :, :].max()}')
            elif filetype == 'mpas':
                print(
                    f'  Input layer {z}, layer {InputFieldName} min/max: '
                    f'{InputField[z, :, :].min()} {InputField[z, :, :].max()}')
                # Call the appropriate routine for actually doing the
                # interpolation
                if args.interpType == 'b':
                    print(f"  ...Layer {z}, Interpolating this layer to MPAS "
                          f"grid using built-in bilinear method...")
                    mpas_grid_input_layers[z, :] = _bilinear_interp(
                        InputField[z, :, :],
                        fieldInfo[MPASfieldName]['gridType'])
                elif args.interpType == 'd':
                    print(f"  ...Layer {z}, Interpolating this layer to MPAS "
                          f"grid using built-in barycentric method...")
                    if filetype == 'cism':
                        mpas_grid_input_layers[z, :] = _delaunay_interpolate(
                            InputField[z, :, :],
                            fieldInfo[MPASfieldName]['gridType'])
                    elif filetype == 'mpas':
                        mpas_grid_input_layers[z, :] = _delaunay_interpolate(
                            InputField[:, z],
                            fieldInfo[MPASfieldName]['gridType'])
                elif args.interpType == 'n':
                    print(f"  ...Layer {z}, Interpolating this layer to MPAS "
                          f"grid using nearest neighbor method...")
                    if fieldInfo[MPASfieldName]['gridType'] == 'x0':
                        # 2d cism fields need to be flattened. (Note the
                        # indices were flattened during init, so this just
                        # matches that operation for the field data itself.)
                        # 1d mpas fields do not, but the operation won't do
                        # anything because they are already flat.
                        mpas_grid_input_layers[z, :] = \
                            InputField[z, :, :].flatten()[nn_idx_x0]
                    elif fieldInfo[MPASfieldName]['gridType'] == 'x1':
                        # 2d cism fields need to be flattened. (Note the
                        # indices were flattened during init, so this just
                        # matches that operation for the field data itself.)
                        # 1d mpas fields do not, but the operation won't do
                        # anything because they are already flat.
                        mpas_grid_input_layers[z, :] = \
                            InputField[z, :, :].flatten()[nn_idx_x1]
                    elif fieldInfo[MPASfieldName]['gridType'] == 'cell':
                        # 2d cism fields need to be flattened. (Note the
                        # indices were flattened during init, so this just
                        # matches that operation for the field data itself.)
                        # 1d mpas fields do not, but the operation won't do
                        # anything because they are already flat.
                        mpas_grid_input_layers[z, :] = \
                            InputField[:, z].flatten()[nn_idx_cell]
                elif args.interpType == 'e':
                    print(f"  ...Layer {z}, Interpolating this layer to MPAS "
                          f"grid using ESMF-weights method...")
                    if filetype == 'cism':
                        mpas_grid_input_layers[z, :] = \
                            _esmf_interp(InputField[z, :, :])
                    elif filetype == 'mpas':
                        mpas_grid_input_layers[z, :] = \
                            _esmf_interp(InputField[:, z])
            else:
                raise ValueError('Unknown interpolation method specified')
            print(f'  interpolated MPAS {MPASfieldName}, layer {z} min/max: '
                  f'{mpas_grid_input_layers[z, :].min()} '
                  f'{mpas_grid_input_layers[z, :].max()}')

        if fieldInfo[MPASfieldName]['scalefactor'] != 1.0:
            mpas_grid_input_layers *= fieldInfo[MPASfieldName]['scalefactor']
            print(f'  scaled MPAS {MPASfieldName} on CISM vertical layers, '
                  f'min/max: {mpas_grid_input_layers.min()} '
                  f'{mpas_grid_input_layers.max()}')
        if fieldInfo[MPASfieldName]['offset'] != 0.0:
            mpas_grid_input_layers += fieldInfo[MPASfieldName]['offset']
            print(f'  offset MPAS {MPASfieldName} on CISM vertical layers, '
                  f'min/max: {mpas_grid_input_layers.min()} '
                  f'{mpas_grid_input_layers.max()}')

        # ------------
        # Now interpolate vertically
        print(f"  Input layer field "
              f"{inputFile.variables[InputFieldName].dimensions[1]} has "
              f"layers: {input_layers}")
        if 'nVertLevels' in MPASfile.variables[MPASfieldName].dimensions:
            print(f"  MPAS layer centers are: {mpasLayerCenters}")
            destVertCoord = mpasLayerCenters
        elif 'nVertInterfaces' in MPASfile.variables[MPASfieldName].dimensions:
            print(f"  MPAS layer interfaces are: {mpasLayerInterfaces}")
            destVertCoord = mpasLayerInterfaces
        else:
            raise ValueError("Unknown vertical dimension for this variable "
                             "destination file.")

        if input_layers.min() > destVertCoord.min():
            # This fix ensures that interpolation is done when
            # input_layers.min is very slightly greater than destVertCoord.min
            if input_layers.min() - 1.0e-6 < destVertCoord.min():
                print(f'input_layers.min = {input_layers.min():.16f}')
                print(f'destVertCoord.min = {destVertCoord.min():.16f}')
                input_layers[0] = input_layers[0] - 1.0e-6
                print(f'New input_layers.min = {input_layers.min():.16f}')
            else:
                print("WARNING: input_layers.min() > destVertCoord.min()   "
                      "Values at the first level of input_layers will be used "
                      "for all MPAS layers in this region!")
        if input_layers.max() < destVertCoord.max():
            # This fix ensures that interpolation is done when
            # input_layers.max is very slightly smaller than destVertCoord.max
            if input_layers.max() + 1.0e-6 > destVertCoord.min():
                print(f'input_layers.max = {input_layers.max():.16f}')
                print(f'destVertCoord.max = {destVertCoord.max():.16f}')
                input_layers[inputVerticalDimSize-1] = \
                    input_layers[inputVerticalDimSize-1] + 1.0e-6
                print(f'New input_layers.max = {input_layers.max():.16f}')
                print(f'input_layers = {input_layers}')
            else:
                print("WARNING: input_layers.max() < destVertCoord.max()   "
                      "Values at the last level of input_layers will be used "
                      "for all MPAS layers in this region!")
        MPASfield = _vertical_interp_mpas_grid(mpas_grid_input_layers,
                                               destVertCoord, input_layers)
        print(f'  MPAS {MPASfieldName} on MPAS vertical layers, min/max of '
              f'all layers: {MPASfield.min()}, {MPASfield.max()}')

        del mpas_grid_input_layers

        return MPASfield

    # ----------------------------

    def _vertical_interp_mpas_grid(mpas_grid_input_layers, destVertCoord,
                                   input_layers):
        destinationField = np.zeros((nCells, len(destVertCoord)))
        for i in range(nCells):
            destinationField[i, :] = np.interp(destVertCoord, input_layers,
                                               mpas_grid_input_layers[:, i])
        return destinationField

    # ----------------------------
    # ----------------------------

    print("== Gathering information.  (Invoke with --help for more details. "
          "All arguments are optional)\n")
    parser = argparse.ArgumentParser(
       formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.description = __doc__
    parser.add_argument(
       "-s", "--source", dest="inputFile",
       help="name of source (input) file.  Can be either CISM format or "
            "MPASLI format.",
       default="cism.nc", metavar="FILENAME")
    parser.add_argument(
       "-d", "--destination", dest="mpasFile",
       help="name of destination file on which to interpolate fields.  This "
            "needs to be MPASLI format with desired fields already existing.",
       default="landice_grid.nc", metavar="FILENAME")
    parser.add_argument(
       "-m", "--method", dest="interpType",
       help="interpolation method to use. b=bilinear, d=barycentric, e=ESMF, "
            "n=nearest neighbor",
       default="b", metavar="METHOD")
    parser.add_argument(
       "-w", "--weight", dest="weightFile",
       help="ESMF weight file to input.  Only used by ESMF interpolation "
            "method",
       metavar="FILENAME")
    parser.add_argument(
       "-t", "--thickness-only", dest="thicknessOnly", action="store_true",
       default=False,
       help="Only interpolate thickness and ignore all other variables "
            "(useful for setting up a cullMask)")
    parser.add_argument(
       "--timestart", dest="timestart", type=int, default=0,
       help="time level in input file to start from (0-based)")
    parser.add_argument(
       "--timeend", dest="timeend", type=int, default=0,
       help="time level in input file to end with (0-based, inclusive)")
    parser.add_argument(
       "-v", "--variables", dest="vars", nargs='*', type=str, default="all",
       help="Variables in the destination mesh for which interpolation should "
            "be attempted.  Interpolation will only actually occur if the "
            "requested field 1) is in the dictionary of supported fields at "
            "the end of this script and 2) exists in both the source and "
            "destination files.  'all' can be used to attempt to interpolate "
            "all fields present in the destination mesh.  Provide a "
            "space-delimited list.")
    args = parser.parse_args()

    print(f"  Source file:  {args.inputFile}")
    print(f"  Destination MPASLI file to be modified:  {args.mpasFile}")

    print(f"  Interpolation method to be used:  {args.interpType}")
    print("    (b=bilinear, d=barycentric, e=esmf)")

    if args.weightFile and args.interpType == 'e':
        print(f"  Interpolation will be performed using ESMF-weights method, "
              f"where possible, using weights file:  {args.weightFile}")
        # ----------------------------
        # Get weights from file
        wfile = netCDF4.Dataset(args.weightFile, 'r')
        S = wfile.variables['S'][:]
        col = wfile.variables['col'][:]
        row = wfile.variables['row'][:]
        n_a = len(wfile.dimensions['n_a'])
        n_b = len(wfile.dimensions['n_b'])
        dst_frac = wfile.variables['frac_b'][:]
        wfile.close()
        # ----------------------------

        # convert to SciPy Compressed Sparse Row (CSR) matrix format
        weights_csr = scipy.sparse.coo_array((S, (row - 1, col - 1)),
                                             shape=(n_b, n_a)).tocsr()

    # make a space in stdout before further output
    print('')

    print("==================")
    print('Gathering coordinate information from input and output files.')

    # Open the output file, get needed dimensions & variables
    try:
        MPASfile = netCDF4.Dataset(args.mpasFile, 'r+')
        MPASfile.set_auto_mask(False)
        try:
            nVertLevels = len(MPASfile.dimensions['nVertLevels'])
        except:
            print('Output file is missing the dimension nVertLevels.  Might '
                  'not be a problem.')
        try:
            nVertInterfaces = len(MPASfile.dimensions['nVertInterfaces'])
        except:
            print('Output file is missing the dimension nVertInterfaces.  '
                  'Might not be a problem.')

        try:
            # 1d vertical fields - layer centers
            layerThicknessFractions = \
                MPASfile.variables['layerThicknessFractions'][:]
            # build up sigma levels
            mpasLayerCenters = np.zeros((nVertLevels,))
            mpasLayerCenters[0] = 0.5 * layerThicknessFractions[0]
            for k in range(nVertLevels)[1:]:  # skip the first level
                mpasLayerCenters[k] = (
                    mpasLayerCenters[k-1] +
                    0.5 * layerThicknessFractions[k-1] +
                    0.5 * layerThicknessFractions[k])
            print(f"  Using MPAS layer centers at sigma levels: "
                  f"{mpasLayerCenters}")
        except:
            print('Trouble calculating mpas layer centers. Might not be a '
                  'problem.')

        try:
            # 1d vertical field - layer interfaces
            layerThicknessFractions = \
                MPASfile.variables['layerThicknessFractions'][:]
            # build up sigma levels
            mpasLayerInterfaces = np.zeros((nVertInterfaces,))
            mpasLayerInterfaces[0] = 0.0
            for k in range(1, nVertInterfaces):  # skip the first level
                mpasLayerInterfaces[k] = (
                    mpasLayerInterfaces[k-1] + layerThicknessFractions[k-1])
            print(f"  Using MPAS layer interfaces at sigma levels: "
                  f"{mpasLayerInterfaces}")
        except:
            print('Trouble calculating mpas layer interfaces. Might not be a '
                  'problem.')

        # '2d' spatial fields on cell centers
        xCell = MPASfile.variables['xCell'][:]
        # print('xCell min/max:', xCell.min(), xCell.max()
        yCell = MPASfile.variables['yCell'][:]
        # print('yCell min/max:', yCell.min(), yCell.max()
        nCells = len(MPASfile.dimensions['nCells'])

    except:
        raise ValueError('The output grid file specified is either missing '
                         'or lacking needed dimensions/variables.')
    print("==================\n")

    # Open the input file, get needed dimensions
    inputFile = netCDF4.Dataset(args.inputFile, 'r')
    inputFile.set_auto_mask(False)

    # Figure out if this is CISM or MPAS
    if 'x1' in inputFile.variables:
        filetype = 'cism'
        print("Source file appears to be in CISM format.")
    elif 'xCell' in inputFile.variables:
        filetype = 'mpas'
        print("Source file appears to be in MPAS format.")
    else:
        filetype = 'other'
        print("Source file appears to be in a non-standard format.")
        if not args.interpType == 'e':
            raise ValueError("Source file does not appear to be a CISM file "
                             "or an MPAS file.  The ESMF interpolation method "
                             "is the only supported method for files with a "
                             "non-standard format.")

    if filetype == 'cism':
        # Get the CISM vertical dimensions if they exist
        try:
            level = len(inputFile.dimensions['level'])
        except:
            print('  Input file is missing the dimension level.  Might not be '
                  'a problem.')

        try:
            stagwbndlevel = len(inputFile.dimensions['stagwbndlevel'])
        except:
            print('  Input file is missing the dimension stagwbndlevel.  '
                  'Might not be a problem.')

        # Get CISM location variables if they exist
        try:
            x1 = inputFile.variables['x1'][:]
            dx1 = x1[1] - x1[0]
            # print('x1 min/max/dx:', x1.min(), x1.max(), dx1
            y1 = inputFile.variables['y1'][:]
            dy1 = y1[1] - y1[0]
            # print('y1 min/max/dx:', y1.min(), y1.max(), dy1

            # This was for some shifted CISM grid but should not be used in
            # general.
            # #x1 = x1 - (x1.max()-x1.min())/2.0
            # #y1 = y1 - (y1.max()-y1.min())/2.0
        except:
            print('  Input file is missing x1 and/or y1.  Might not be a '
                  'problem.')

        try:
            x0 = inputFile.variables['x0'][:]
            # print('x0 min/max:', x0.min(), x0.max()
            y0 = inputFile.variables['y0'][:]
            # print('y0 min/max:', y0.min(), y0.max()

            # #x0 = x0 - (x0.max()-x0.min())/2.0
            # #y0 = y0 - (y0.max()-y0.min())/2.0

        except:
            print('  Input file is missing x0 and/or y0.  Might not be a '
                  'problem.')

        # Check the overlap of the grids
        print('==================')
        print('CISM Input File extents:')
        print('  x1 min, max:    {} {}'.format(x1.min(), x1.max()))
        print('  y1 min, max:    {} {}'.format(y1.min(), y1.max()))
        print('MPAS File extents:')
        print('  xCell min, max: {} {}'.format(xCell.min(), xCell.max()))
        print('  yCell min, max: {} {}'.format(yCell.min(), yCell.max()))
        print('==================')

    elif filetype == 'mpas':

        # try:
        #     nVertInterfaces = len(inputFile.dimensions['nVertInterfaces'])
        # except:
        #     print('  Input file is missing the dimension nVertInterfaces.  '
        #           'Might not be a problem.'

        # Get MPAS location variables if they exist
        try:
            inputxCell = inputFile.variables['xCell'][:]
            inputyCell = inputFile.variables['yCell'][:]
        except:
            raise ValueError("Input file is missing xCell and/or yCell")

        # Check the overlap of the grids
        print('==================')
        print('Input MPAS File extents:')
        print(f'  xCell min, max:    {inputxCell.min()} {inputxCell.max()}')
        print(f'  yCell min, max:    {inputyCell.min()} {inputyCell.max()}')
        print('Output MPAS File extents:')
        print(f'  xCell min, max: {xCell.min()} {xCell.max()}')
        print(f'  yCell min, max: {yCell.min()} {yCell.max()}')
        print('==================')

    if filetype == 'mpas' and args.interpType == 'b':
        raise ValueError("Bilinear interpolation not supported for input "
                         "files of MPAS format.")

    # ----------------------------
    # Setup Delaunay/barycentric interpolation weights if needed
    if args.interpType == 'd':
        mpasXY = np.vstack((xCell[:], yCell[:])).transpose()

        if filetype == 'cism':
            [Yi, Xi] = np.meshgrid(x1[:], y1[:])
            cismXY1 = np.zeros([Xi.shape[0]*Xi.shape[1],2])
            cismXY1[:, 0] = Yi.flatten()
            cismXY1[:, 1] = Xi.flatten()

            print('\nBuilding interpolation weights: CISM x1/y1 -> MPAS')
            start = time.perf_counter()
            vtx1, wts1, outsideIndx1, treex1 = \
                _delaunay_interp_weights(cismXY1, mpasXY)
            if len(outsideIndx1) > 0:
                outsideIndx1 = outsideIndx1[0]  # get the list itself
            end = time.perf_counter()
            print(f'done in {end - start}')

            if 'x0' in inputFile.variables and not args.thicknessOnly:
                # Need to setup separate weights for this grid
                [Yi, Xi] = np.meshgrid(x0[:], y0[:])
                cismXY0 = np.zeros([Xi.shape[0]*Xi.shape[1], 2])
                cismXY0[:, 0] = Yi.flatten()
                cismXY0[:, 1] = Xi.flatten()

                print('Building interpolation weights: CISM x0/y0 -> MPAS')
                start = time.perf_counter()
                vtx0, wts0, outsideIndx0, treex0 = \
                    _delaunay_interp_weights(cismXY0, mpasXY)
                if len(outsideIndx0) > 0:
                    outsideIndx0 = outsideIndx0[0]  # get the list itself
                end = time.perf_counter()
                print(f'done in {end - start}')

        elif filetype == 'mpas':
            inputmpasXY = np.vstack((inputxCell[:], inputyCell[:])).transpose()
            print('Building interpolation weights: MPAS in -> MPAS out')
            start = time.perf_counter()
            vtCell, wtsCell, outsideIndcell, treecell = \
                _delaunay_interp_weights(inputmpasXY, mpasXY)
            end = time.perf_counter()
            print(f'done in {end - start}')

    # ----------------------------
    # Setup NN interpolation weights if needed
    if args.interpType == 'n':
        mpasXY = np.vstack((xCell[:], yCell[:])).transpose()

        if filetype == 'cism':
            [Yi, Xi] = np.meshgrid(x1[:], y1[:])
            cismXY1 = np.zeros([Xi.shape[0]*Xi.shape[1], 2])
            cismXY1[:, 0] = Yi.flatten()
            cismXY1[:, 1] = Xi.flatten()

            print('\nBuilding interpolation weights: CISM x1/y1 -> MPAS')
            start = time.perf_counter()
            nn_idx_x1 = _nn_interp_weights(cismXY1, mpasXY)
            end = time.perf_counter()
            print('done in {}'.format(end-start))

            if 'x0' in inputFile.variables and not args.thicknessOnly:
                # Need to setup separate weights for this grid
                [Yi, Xi] = np.meshgrid(x0[:], y0[:])
                cismXY0 = np.zeros([Xi.shape[0]*Xi.shape[1], 2])
                cismXY0[:, 0] = Yi.flatten()
                cismXY0[:, 1] = Xi.flatten()

                print('Building interpolation weights: CISM x0/y0 -> MPAS')
                start = time.perf_counter()
                nn_idx_x0 = _nn_interp_weights(cismXY0, mpasXY)
                end = time.perf_counter()
                print('done in {}'.format(end-start))

        elif filetype == 'mpas':
            inputmpasXY = np.vstack((inputxCell[:], inputyCell[:])).transpose()
            print('Building interpolation weights: MPAS in -> MPAS out')
            start = time.perf_counter()
            nn_idx_cell = _nn_interp_weights(inputmpasXY, mpasXY)
            end = time.perf_counter()
            print('done in {}'.format(end-start))

    # ----------------------------
    # Map Input-Output field names - add new fields here as needed

    fieldInfo = OrderedDict()
    # -----------------
    if filetype == 'cism':

        fieldInfo['thickness'] = {
            'InputName': 'thk',
            'scalefactor': 1.0,
            'offset': 0.0,
            'gridType': 'x1',
            'vertDim': False}
        fieldInfo['iceMask'] = {
            'InputName': 'iceMask',
            'scalefactor': 1.0,
            'offset': 0.0,
            'gridType': 'x1',
            'vertDim': False}
        if not args.thicknessOnly:
            fieldInfo['bedTopography'] = {
                'InputName': 'topg',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            # Assuming mm/yr w.e. units for smb
            fieldInfo['sfcMassBal'] = {
                'InputName': 'smb',
                'scalefactor': 1.0/(3600.0*24.0*365.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            # Assuming mm/yr w.e. units for smb
            fieldInfo['sfcMassBalUncertainty'] = {
                'InputName': 'smb_std',
                'scalefactor': 1.0/(3600.0*24.0*365.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            # Assuming default CISM density
            fieldInfo['floatingBasalMassBal'] = {
                'InputName': 'subm',
                'scalefactor': 910.0/(3600.0*24.0*365.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            # # pick one or the other:
            # fieldInfo['temperature'] = {
            #     'InputName': 'temp',
            #     'scalefactor': 1.0,
            #     'offset': 273.15,
            #     'gridType': 'x1',
            #     'vertDim': True}
            fieldInfo['temperature'] = {
                'InputName': 'tempstag',
                'scalefactor': 1.0,
                'offset': 273.15,
                'gridType': 'x1',
                'vertDim': True}
            fieldInfo['basalHeatFlux'] = {
                'InputName': 'bheatflx',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['surfaceAirTemperature'] = {
                'InputName': 'artm',
                'scalefactor': 1.0,
                'offset': 273.15,
                'gridType': 'x1',
                'vertDim': False}
            # needs different mapping file...
            fieldInfo['beta'] = {
                'InputName': 'beta',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x0',
                'vertDim': False}
            # # needs different mapping file...
            # fieldInfo['observedSpeed'] = {
            #     'InputName': 'balvel',
            #     'scalefactor': 1.0/(365.0*24.0*3600.0),
            #     'offset': 0.0,
            #     'gridType': 'x0',
            #     'vertDim': False}
            # fields for observed surface speed and associated error, observed
            # thickness change
            fieldInfo['observedSurfaceVelocityX'] = {
                'InputName': 'vx',
                'scalefactor': 1.0/(365.0*24.0*3600.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['observedSurfaceVelocityY'] = {
                'InputName': 'vy',
                'scalefactor': 1.0/(365.0*24.0*3600.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['observedSurfaceVelocityUncertainty'] = {
                'InputName': 'vErr',
                'scalefactor': 1.0/(365.0*24.0*3600.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['observedThicknessTendency'] = {
                'InputName': 'dHdt',
                'scalefactor': 1.0/(365.0*24.0*3600.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['observedThicknessTendencyUncertainty'] = {
                'InputName': 'dHdtErr',
                'scalefactor': 1.0/(365.0*24.0*3600.0),
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['thicknessUncertainty'] = {
                'InputName': 'topgerr',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}

            fieldInfo['ismip6shelfMelt_basin'] = {
                'InputName': 'ismip6shelfMelt_basin',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}
            fieldInfo['ismip6shelfMelt_deltaT'] = {
                'InputName': 'ismip6shelfMelt_deltaT',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'x1',
                'vertDim': False}

    # -----------------
    elif filetype == 'mpas':

        fieldInfo['thickness'] = {
            'InputName': 'thickness',
            'scalefactor': 1.0,
            'offset': 0.0,
            'gridType': 'cell',
            'vertDim': False}
        if not args.thicknessOnly:
            fieldInfo['bedTopography'] = {
                'InputName': 'bedTopography',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['sfcMassBal'] = {
                'InputName': 'sfcMassBal',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['floatingBasalMassBal'] = {
                'InputName': 'floatingBasalMassBal',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['temperature'] = {
                'InputName': 'temperature',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': True}
            fieldInfo['basalHeatFlux'] = {
                'InputName': 'basalHeatFlux',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['surfaceAirTemperature'] = {
                'InputName': 'surfaceAirTemperature',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['beta'] = {
                'InputName': 'beta',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['muFriction'] = {
                'InputName': 'muFriction',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['eigencalvingParameter'] = {
                'InputName': 'eigencalvingParameter',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            # obs fields
            fieldInfo['observedSurfaceVelocityX'] = {
                'InputName': 'observedSurfaceVelocityX',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['observedSurfaceVelocityY'] = {
                'InputName': 'observedSurfaceVelocityY',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['observedSurfaceVelocityUncertainty'] = {
                'InputName': 'observedSurfaceVelocityUncertainty',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['observedThicknessTendency'] = {
                'InputName': 'observedThicknessTendency',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['observedThicknessTendencyUncertainty'] = {
                'InputName': 'observedThicknessTendencyUncertainty',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['thicknessUncertainty'] = {
                'InputName': 'thicknessUncertainty',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['basalFrictionFlux'] = {
                'InputName': 'basalFrictionFlux',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['uReconstructX'] = {
                'InputName': 'uReconstructX',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': True}
            fieldInfo['uReconstructY'] = {
                'InputName': 'uReconstructY',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': True}

            fieldInfo['ismip6shelfMelt_basin'] = {
                'InputName': 'ismip6shelfMelt_basin',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['ismip6shelfMelt_deltaT'] = {
                'InputName': 'ismip6shelfMelt_deltaT',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}

            fieldInfo['stiffnessFactor'] = {
                'InputName': 'stiffnessFactor',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['effectivePressure'] = {
                'InputName': 'effectivePressure',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}
            fieldInfo['iceMask'] = {
                'InputName': 'iceMask',
                'scalefactor': 1.0,
                'offset': 0.0,
                'gridType': 'cell',
                'vertDim': False}

        # Used by Trevor
        #     fieldInfo['sfcMassBalUncertainty'] = {
        #         'InputName': 'smb_std_vector',
        #         'scalefactor': 910.0/(3600.0*24.0*365.0)/1000.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['ismip6Runoff'] = {
        #         'InputName': 'runoff_vector',
        #         'scalefactor': 1.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['ismip6_2dThermalForcing'] = {
        #         'InputName': 'thermal_forcing_vector',
        #         'scalefactor': 1.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['ismip6aST'] = {
        #         'InputName': 'aST_vector',
        #         'scalefactor': 1.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['ismip6aSMB'] = {
        #         'InputName': 'aSMB_vector',
        #         'scalefactor': 1.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['ismip6refST'] = {
        #         'InputName': 'ST_vector',
        #         'scalefactor': 1.0,
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}
        #     fieldInfo['externalWaterInput'] = {
        #         'InputName': 'externalWaterInput_vector',
        #         'scalefactor': 1.0/(3600.0*24.0*365.0),
        #         'offset': 0.0,
        #         'gridType': 'cell',
        #         'vertDim': False}

    # -----------------
    elif filetype == 'other':
        # These are variable mappings for the ESMF method.  Update as needed
        # for specific applications.

        # This example can be used with an ELM history file and an EMSF mapping
        # file.
        fieldInfo['surfaceAirTemperature'] = {
            'InputName': 'TBOT',
            'scalefactor': 1.0,
            'offset': 0.0,
            'gridType': 'cell',
            'vertDim': False}

    else:
        raise ValueError("Unknown file type.")

    # ----------------------------

    # ----------------------------
    # try each field.  If it exists in the input file, it will be copied.  If
    # not, it will be skipped.
    interpolated_vars = []
    for MPASfieldName in fieldInfo:
        if 'all' not in args.vars and MPASfieldName not in args.vars:
            continue

        print('\n## {} ##'.format(MPASfieldName))

        if MPASfieldName not in MPASfile.variables:
            print(f"  Warning: Field '{MPASfieldName}' is not in the "
                  f"destination file.  Skipping.")
            # skip the rest of this iteration of the for loop over variables
            continue

        if fieldInfo[MPASfieldName]['InputName'] not in inputFile.variables:
            print(f"  Warning: Field '{fieldInfo[MPASfieldName]['InputName']}'"
                  f" is not in the source file.  Skipping.")
            # skip the rest of this iteration of the for loop over variables
            continue

        for timelev in range(args.timestart, args.timeend+1):
            # Note: the interpolate functions called below access timelev as a
            #       global variable
            #
            # assuming the time level of the output file should match that of
            # the input file
            timelevout = timelev
            print(f"    ---- Interpolating time level {timelev} ----")
            start = time.perf_counter()
            if fieldInfo[MPASfieldName]['vertDim']:
                MPASfield = _interpolate_field_with_layers(MPASfieldName)
            else:
                MPASfield = _interpolate_field(MPASfieldName)
            end = time.perf_counter()
            print(f'  interpolation done in {end - start}')

            # Don't allow negative thickness.
            if MPASfieldName == 'thickness' and MPASfield.min() < 0.0:
                MPASfield[MPASfield < 0.0] = 0.0
                print(f'  removed negative thickness, new min/max: '
                      f'{MPASfield.min()} {MPASfield.max()}')

            # basalHeatFlux must be non-negative
            if MPASfieldName == 'basalHeatFlux':
                assert np.nanmin(MPASfield) >= 0.0, \
                    'basalHeatFlux contains negative values! This is likely ' \
                    'due to the conventions used in the input file, rather ' \
                    'than bad data. Ensure non-negative values before ' \
                    'interpolating.'

            # Now insert the MPAS field into the file.
            if 'Time' in MPASfile.variables[MPASfieldName].dimensions:
                # Time will always be leftmost index
                MPASfile.variables[MPASfieldName][timelevout, :] = MPASfield
            else:
                MPASfile.variables[MPASfieldName][:] = MPASfield

            # update the file now in case we get an error later
            MPASfile.sync()
        interpolated_vars.append(MPASfieldName)

    if args.timeend > args.timestart:
        print("\n\nMultiple time levels have been copied, but xtime has not.  "
              "Be sure to manually copy or assign xtime values in the "
              "destination file if needed.")

    print("\nFields successfully interpolated: " + ",".join(interpolated_vars))

    # Update history attribute of netCDF file
    thiscommand = datetime.now().strftime("%a %b %d %H:%M:%S %Y") + ": " + \
        " ".join(sys.argv[:])  # .join("Variables interpolated: {}".format(interpolated_vars))
    thiscommand = thiscommand+";  Variables successfully interpolated: " + \
        ",".join(interpolated_vars)
    if hasattr(MPASfile, 'history'):
        newhist = '\n'.join([thiscommand, getattr(MPASfile, 'history')])
    else:
        newhist = thiscommand
    setattr(MPASfile, 'history', newhist)

    inputFile.close()
    MPASfile.close()

    print('\nInterpolation completed.')
